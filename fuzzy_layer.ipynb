{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Xzl6-uaSTbBO"},"outputs":[],"source":["import pandas as pd\n","import networkx as nx\n","import torch\n","import random\n","from pathlib import Path\n","import numpy as np\n","from typing import Any"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lJkPVar8TbBR","outputId":"589391c3-dddb-4cc5-fe11-949b38b27578"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n","\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_DlXFo7eTbBS"},"outputs":[],"source":["dataset = \"/Users/vanshgupta/Desktop/AI and ML reading material/GraphGAN_Project/GraphGAN/bio-grid-human/bio-grid-human_dataset.txt1\" # used to generate graph and get the number of nodes\n","filename = \"/Users/vanshgupta/Desktop/AI and ML reading material/GraphGAN_Project/Emb and Data/Emb/biogrid-human/DeepWalk/emb.txt\" # used to read the file and get embeddings.\n","error_emb_filename = \"/Users/vanshgupta/Desktop/AI and ML reading material/GraphGAN_Project/Emb and Data/Emb/biogrid-human/DeepWalk/emb_10%_error.txt\" # path where you want to save the embeddings with induced errors.\n","embedding_filename = \"/Users/vanshgupta/Desktop/AI and ML reading material/GraphGAN_Project/Emb and Data/Emb/biogrid-human/DeepWalk/fuzzy_emb_10%_error.txt\" # filepath where you want to store the fuzzy layer processed embeddings\n","\n","k = 5 # k -> Number of clusters\n","node_embed_dim = 50 # Dimension of node feature vector\n","\n","rng = np.random.default_rng(seed = 42) # set seed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QUueZX9ETbBT"},"outputs":[],"source":["def add_noise(x : torch.Tensor, noise_ratio : float, node_embed_dim : int) -> torch.Tensor:\n","    \"\"\"\n","    Adds Gaussian noise to a subset of nodes in a given tensor.\n","\n","    This function introduces noise to a fraction of the nodes in the input tensor `x`. The noise is\n","    generated from a normal distribution with mean 0 and standard deviation 1. The number of nodes\n","    to be noised is determined by the `noise_ratio` parameter.\n","\n","    Parameters:\n","        x (torch.Tensor): The input tensor of shape `(num_nodes, node_embed_dim)` representing\n","                          node embeddings.\n","        noise_ratio (float): The fraction of nodes to which noise will be added. Should be a\n","                             value between 0 and 1.\n","        node_embed_dim (int): The dimensionality of the node embeddings.\n","\n","    Returns:\n","        torch.Tensor: The modified tensor `x` with noise added to a subset of nodes.\n","\n","    \"\"\"\n","\n","\n","    num_nodes = x.shape[0] #fetch the number of nodes\n","    num_nodes_to_add_noise = int(num_nodes * noise_ratio) #fetch the number of nodes that are to be noised\n","    total_nodes = torch.arange(0 , num_nodes).tolist() #gives a list of nodes\n","    nodes_to_noise = random.sample(total_nodes, num_nodes_to_add_noise) #gives the node-ids where noise is to be added.\n","\n","    noise_tensor = torch.normal(mean = 0,\n","                                std = 1,\n","                                size = (num_nodes_to_add_noise, node_embed_dim))\n","\n","    x[nodes_to_noise] = noise_tensor\n","    return x\n","\n","\n","def read_embeddings(filename: Path, n_node: int, n_embed: int) -> np.ndarray:\n","    \"\"\"\n","    Reads pretrained node embeddings from a file and returns them as a numpy array.\n","\n","    This function initializes an embedding matrix with random values and updates it with\n","    the pretrained embeddings provided in the file. If a node does not have a pretrained\n","    embedding in the file, its embedding will remain as the initialized random values.\n","\n","    Parameters:\n","        filename (Path): Path to the file containing pretrained node embeddings.\n","                         The file format is expected to have node embeddings on each\n","                         line in the format: `node_id dim_1 dim_2 ... dim_n`, with the\n","                         first line typically skipped (header).\n","        n_node (int): The total number of nodes in the graph.\n","        n_embed (int): The embedding dimensionality for each node.\n","\n","    Returns:\n","        np.ndarray: A numpy array of shape `(n_node, n_embed)` representing the node embeddings.\n","\n","    \"\"\"\n","\n","    # Open the file and read all lines, skipping the first line (header)\n","    with open(filename, \"r\") as f:\n","        lines = f.readlines()[1:]\n","\n","        # Create an embedding matrix initialized with random normal values\n","        embedding_matrix = rng.standard_normal(size=(n_node, n_embed))\n","\n","        # Iterate over each line in the file (representing a node embedding)\n","        for line in lines:\n","            emd = line.split()  # Split the line into node ID and embedding values\n","            # Update the embedding matrix for the specific node ID\n","            embedding_matrix[int(emd[0]), :] = str_list_to_float(emd[1:])\n","\n","        # Return the final embedding matrix\n","        return embedding_matrix\n","\n","def save_embeddings(filepath : Path, graph : Any, embeddings : np.ndarray) -> None:\n","    \"\"\"\n","    Saves node embeddings to a file in a specified format.\n","\n","    This function takes a graph, its corresponding embeddings, and a file path. It maps the\n","    embeddings to the graph nodes, combines the node indices with their respective embeddings,\n","    and writes the data to the file. The output file includes a header indicating the total\n","    number of nodes and the embedding dimensionality, followed by the embeddings for each node.\n","\n","    Parameters:\n","        filepath (Path): Path to the file where embeddings will be saved.\n","        graph (Any): A graph object (e.g., from NetworkX) containing node information.\n","        embeddings (np.ndarray): A 2D numpy array of shape `(num_nodes, embedding_dim)`\n","                                  containing node embeddings.\n","\n","    File Format:\n","        The saved file has the following format:\n","        - The first line contains the number of nodes and the embedding dimensionality,\n","          separated by a tab.\n","        - Each subsequent line corresponds to a node, containing the node ID followed\n","          by its embedding values separated by spaces.\n","    \"\"\"\n","    # Map the embeddings to the node indices in the graph\n","    new = embeddings[torch.tensor(np.array(graph.nodes()))]\n","\n","    # Get the node indices and reshape them into a column vector\n","    index = np.array(graph.nodes()).reshape(-1, 1)\n","\n","    # Combine node indices with their embeddings into a single matrix\n","    embedding_matrix = np.hstack([index, new])\n","\n","    # Convert the embedding matrix into a list of strings for saving\n","    embedding_list = embedding_matrix.tolist()\n","    embedding_str = [str(int(emb[0])) + \" \" + \" \".join([str(x) for x in emb[1:]]) + \"\\n\"\n","                     for emb in embedding_list]\n","\n","    # Write the embeddings to the file\n","    with open(filepath, \"w+\") as f:\n","        # Include the header with number of nodes and embedding dimensionality\n","        lines = [str(graph.number_of_nodes()) + \"\\t\" + str(embeddings.shape[1]) + \"\\n\"] + embedding_str\n","        f.writelines(lines)\n","\n","\n","def str_list_to_float(str_list : list[str]) -> list[float]:\n","    \"\"\"Convert the string items of a list to float items\"\"\"\n","    return [float(item) for item in str_list]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dFvC4U5JTbBU","outputId":"456e8664-1680-4574-c46d-a054378334e7"},"outputs":[{"data":{"text/plain":["9436"]},"execution_count":183,"metadata":{},"output_type":"execute_result"}],"source":["\n","df = pd.read_csv(dataset,\n","                sep = '\\t',\n","                names = [\"NodeIDfrom\", \"NodeIDto\"])\n","#create the graph networkx object from the above dataframe\n","\n","G = nx.from_pandas_edgelist(df = df,\n","                             source = \"NodeIDfrom\",\n","                             target = \"NodeIDto\",\n","                             create_using=nx.Graph())\n","\n","X = read_embeddings(filename=filename,\n","                                     n_node = len(G),\n","                                     n_embed = 50)\n","\n","print(f\"Number of Nodes in the graph : {len(G)}\")\n","print(f\"The shape of the embedding vector {X.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uS_52A7tTbBU"},"outputs":[],"source":["### ------------------------------------------------------------ TO ADD NOISE ------------------------------------------------------------ ###\n","# Run this when you have to add noise to the original embeddings.\n","X = add_noise(x = X, noise_ratio=0.1, node_embed_dim=50)\n","X = np.array(X)\n","save_embeddings(filepath=error_emb_filename, graph=G, embeddings=X)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YEtXdZYLTbBV"},"outputs":[],"source":["class KMeansNodeClustering:\n","    \"\"\"\n","    Implements K-Means clustering for node embedding vectors.\n","\n","    This class clusters a given set of node embedding vectors into `k` clusters using the\n","    K-Means algorithm. Each node embedding is assigned to the cluster whose centroid\n","    is nearest to it, based on the Euclidean distance.\n","\n","    Attributes:\n","        X (np.ndarray): Dataset consisting of node embeddings of shape (num_nodes, node_embed_dim).\n","        k (int): Number of clusters to form.\n","        node_embed_dim (int): Dimensionality of each node embedding.\n","        centroid (np.ndarray): Centroids of the clusters, updated during training.\n","\n","    Methods:\n","        euclidean_measure(centroid, node_embed):\n","            Static method to compute the Euclidean distance between a centroid and a node embedding.\n","\n","        dimensional_mean(cluster_num, node_embed_dim, cluster_indices, cluster_centres):\n","            Computes the mean embedding vector for a given cluster and updates the cluster center.\n","\n","        fit(max_iterations=200):\n","            Fits the K-Means model to the node embedding vector, returning cluster assignments and indices.\n","    \"\"\"\n","    def __init__(self, X, k, node_embed_dim):\n","        \"\"\"\n","        Initializes the KMeansNodeClustering object.\n","\n","        Parameters:\n","            X (np.ndarray): The input dataset containing node embeddings.\n","            k (int): The number of clusters to create.\n","            node_embed_dim (int): Dimensionality of the node embeddings.\n","        \"\"\"\n","        self.k = k  # Number of clusters\n","        self.X = X  # Dataset of node embeddings\n","        self.node_embed_dim = node_embed_dim  # Embedding dimensionality\n","        self.centroid = None  # Placeholder for cluster centroids\n","\n","    @staticmethod\n","    def euclidean_measure(centroid, node_embed):\n","        \"\"\"\n","        Calculates the Euclidean distance between a centroid and a node embedding.\n","\n","        Parameters:\n","            centroid (np.ndarray): Centroid of a cluster (shape: (k, node_embed_dim)).\n","            node_embed (np.ndarray): Node embedding (shape: (node_embed_dim,)).\n","\n","        Returns:\n","            np.ndarray: Euclidean distances from the node embedding to each centroid.\n","        \"\"\"\n","        return np.sqrt(np.sum((centroid - node_embed) ** 2, axis=1))\n","\n","    @staticmethod\n","    def dimensional_mean(cluster_num, node_embed_dim, cluster_indices, cluster_centres):\n","        \"\"\"\n","        Computes the mean embedding for a given cluster, dimension-wise.\n","\n","        Parameters:\n","            cluster_num (int): The cluster number for which the mean is calculated.\n","            node_embed_dim (int): Dimensionality of the embeddings.\n","            cluster_indices (list): Indices of nodes belonging to each cluster.\n","            cluster_centres (list): List to store the new cluster centroids.\n","\n","        Returns:\n","            None: Updates the cluster_centres list with the mean centroid.\n","        \"\"\"\n","        axis_centre = np.zeros(node_embed_dim)  # Initialize centroid\n","        for i in range(node_embed_dim):  # Iterate over dimensions\n","            y = 0\n","            tup = cluster_indices[cluster_num].shape\n","            shape = tup[0]  # Number of nodes in the cluster\n","            for x in range(shape):  # Sum values for each dimension\n","                y += X[cluster_indices[cluster_num][x]][0][i]\n","            mean = np.mean(y)  # Calculate mean for the dimension\n","            axis_centre[i] += mean\n","        axis_centre = axis_centre / np.linalg.norm(axis_centre)  # Normalize centroid\n","        return cluster_centres.append(axis_centre)\n","\n","    def fit(self, max_iterations=200):\n","        \"\"\"\n","        Fits the K-Means model to the dataset, clustering nodes into `k` clusters.\n","\n","        Parameters:\n","            max_iterations (int): Maximum number of iterations for the K-Means algorithm.\n","\n","        Returns:\n","            y (np.ndarray): Array indicating the cluster assignment for each node.\n","            cluster_indices (np.ndarray): Array of lists, where each list contains\n","                                           the indices of nodes in the respective cluster.\n","        \"\"\"\n","        # Initialize centroids randomly\n","        self.centroid = rng.standard_normal(size=(self.k, self.node_embed_dim))\n","        self.centroid = self.centroid / (np.max(self.centroid))  # Normalize centroids\n","\n","        # K-Means iterations\n","        for _ in range(max_iterations):\n","            y = []  # To store cluster assignments\n","\n","            # Assign each node to the nearest cluster\n","            for node_embed in self.X:\n","                distance = KMeansNodeClustering.euclidean_measure(\n","                    node_embed=np.array(node_embed),\n","                    centroid=self.centroid\n","                )\n","                cluster_num = np.argmin(distance)  # Closest centroid\n","                y.append(cluster_num)\n","\n","            y = np.array(y)  # Convert assignments to a numpy array\n","\n","            # Create lists to store node indices for each cluster\n","            cluster_indices = []\n","            for i in range(self.k):\n","                cluster_indices.append(np.argwhere(y == i))\n","            cluster_indices = np.array(cluster_indices, dtype=object)\n","\n","            # Update cluster centroids\n","            cluster_centres = []\n","            for j, indices in enumerate(cluster_indices):\n","                if len(indices) == 0:  # If cluster is empty, retain old centroid\n","                    cluster_centres.append(self.centroid[j])\n","                else:\n","                    KMeansNodeClustering.dimensional_mean(\n","                        cluster_num=j,\n","                        node_embed_dim=self.node_embed_dim,\n","                        cluster_indices=cluster_indices,\n","                        cluster_centres=cluster_centres\n","                    )\n","\n","            # Update centroids for the next iteration\n","            self.centroid = np.array(cluster_centres)\n","\n","        return y, cluster_indices\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWOeAY0uTbBW"},"outputs":[],"source":["clustered_nodes = KMeansNodeClustering(X = X,\n","                                       k = k,\n","                                       node_embed_dim = node_embed_dim)\n","#cluster_indices_id stores the number_id of the clusters each embeddings is related to\n","#cluster_indices stores all the nodes that belong to one particular cluster, for all the clusters.\n","cluster_indices_id, cluster_indices = clustered_nodes.fit()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nNKE45Z8TbBW"},"outputs":[],"source":["centroid_array = clustered_nodes.centroid #contains the centroids of all the clusteres.\n","centroid_array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gj8n_ee9TbBW"},"outputs":[],"source":["cluster_indices = np.array(cluster_indices, dtype=object)\n","cluster_indices_array = np.array([torch.tensor(np.squeeze(cluster_indices[0], axis = 1)),\n","                                  torch.tensor(np.squeeze(cluster_indices[1], axis = 1)),\n","                                  torch.tensor(np.squeeze(cluster_indices[2], axis = 1)),\n","                                  torch.tensor(np.squeeze(cluster_indices[3], axis = 1)),\n","                                  torch.tensor(np.squeeze(cluster_indices[4], axis = 1)),\n","                                 ], dtype = object)\n","\n","cluster_indices_array"]},{"cell_type":"code","source":["class Antecedant:\n","    \"\"\"\n","    Implements the antecedent part of the fuzzy logic system. This component computes membership\n","    functions for the node embeddings and handles operations like calculating dot products, means,\n","    variances, and Gaussian Membership Functions (GaussianMF).\n","\n","    Attributes:\n","        X (torch.Tensor): Dataset of node embeddings. Inherited from FuzzyLayer.\n","        centroid_array (torch.Tensor): Array of cluster centroids. Inherited from FuzzyLayer.\n","        cluster_indices_array (list): List of cluster indices. Inherited from FuzzyLayer.\n","\n","    Methods:\n","        dot_product():\n","            Computes the dot product of the dataset `X` with the transposed centroid array.\n","\n","        get_points(cluster_num, embed_axis):\n","            Fetches all points from the dataset corresponding to a given cluster and embedding axis.\n","\n","        get_mean(cluster_num, embed_axis):\n","            Retrieves the mean value (centroid) for a specific cluster and embedding axis.\n","\n","        get_standard_deviation(cluster_num, embed_axis):\n","            Calculates the standard deviation of points in a specific cluster along a specified axis.\n","\n","        get_stddev_tensor(embed_axis):\n","            Computes the standard deviations for all clusters along a specified embedding axis.\n","\n","        gaussianMF(cluster_num, embed_axis, element):\n","            Computes the Gaussian Membership Function (GMF) for a node embedding, given the cluster,\n","            axis, and element value.\n","\n","        get_membership_array(embed_axis):\n","            Generates a membership array for all node embeddings along a specified embedding axis.\n","            Each element represents the membership degree of a node to a cluster.\n","\n","    \"\"\"\n","    def __init__(self, X, centroid_array, cluster_indices_array):\n","              \"\"\"\n","        Initializes the Antecedant object.\n","\n","        Parameters:\n","            X (np.ndarray): Dataset of node embeddings. Shape: (num_nodes, node_embed_dim).\n","            centroid_array (np.ndarray): Centroid array with cluster centroids. Shape: (num_clusters, node_embed_dim).\n","            cluster_indices_array (list): A list of lists, where each sublist contains indices of nodes\n","                                           belonging to a specific cluster.\n","        \"\"\"\n","        self.X = torch.tensor(X, device=device)\n","        self.centroid_array = torch.tensor(centroid_array, device=device)\n","        self.cluster_indices_array = cluster_indices_array\n","\n","    def dot_product(self):\n","        \"\"\"\n","        Computes the dot product of the dataset (X) with the transposed centroid array.\n","\n","        Returns:\n","            torch.Tensor: A matrix where each element represents the dot product of a node embedding\n","                        with a centroid. Shape: (num_nodes, num_clusters).\n","        \"\"\"\n","        # Perform matrix multiplication for efficiency\n","        dot_products = torch.matmul(self.X, self.centroid_array.T)\n","        return dot_products\n","\n","    def get_points(self, cluster_num, embed_axis):\n","        \"\"\"\n","        Fetches all points from the dataset corresponding to a specific cluster and embedding axis.\n","\n","        Args:\n","            cluster_num (int): The index of the cluster whose points need to be retrieved.\n","            embed_axis (int): The specific embedding axis to extract the points from.\n","\n","        Returns:\n","            torch.Tensor: A tensor containing the points of the specified cluster along the given axis.\n","        \"\"\"\n","        # Retrieve node indices belonging to the specified cluster\n","        cluster_ids = torch.tensor(self.cluster_indices_array[cluster_num], device=device)\n","        # Fetch points for the given axis\n","        points = self.X[cluster_ids, embed_axis]\n","        return points\n","\n","    def get_mean(self, cluster_num, embed_axis):\n","        \"\"\"\n","        Retrieves the mean value (centroid) for a specific cluster and embedding axis.\n","\n","        Args:\n","            cluster_num (int): The cluster index.\n","            embed_axis (int): The specific embedding axis.\n","\n","        Returns:\n","            torch.Tensor: The mean value for the specified cluster and axis.\n","        \"\"\"\n","        # Access the mean directly from the centroid array\n","        return self.centroid_array[cluster_num, embed_axis]\n","\n","    def get_standard_deviation(self, cluster_num, embed_axis):\n","        \"\"\"\n","        Computes the standard deviation of points in a specific cluster along a specified axis.\n","\n","        Args:\n","            cluster_num (int): The cluster index.\n","            embed_axis (int): The specific embedding axis.\n","\n","        Returns:\n","            torch.Tensor: The standard deviation of points along the given axis for the specified cluster.\n","        \"\"\"\n","        # Retrieve points for the specified cluster and axis\n","        points = self.get_points(cluster_num, embed_axis)\n","        # Compute the mean\n","        mean = self.get_mean(cluster_num, embed_axis)\n","        # Calculate variance and its square root (standard deviation)\n","        variance = torch.var(points)\n","        variance = torch.sqrt(variance)\n","        return variance\n","\n","    def get_stddev_tensor(self, embed_axis):\n","        \"\"\"\n","        Computes the standard deviations for all clusters along a specified embedding axis.\n","\n","        Args:\n","            embed_axis (int): The embedding axis for which standard deviations are computed.\n","\n","        Returns:\n","            torch.Tensor: A tensor containing the standard deviations for all clusters along the given axis.\n","                        Shape: (num_clusters,).\n","        \"\"\"\n","        # Compute standard deviation for all clusters in a vectorized manner\n","        stddev = torch.tensor([self.get_standard_deviation(cluster_num, embed_axis)\n","                            for cluster_num in range(self.centroid_array.shape[0])], device=device)\n","        return stddev\n","\n","    def gaussianMF(self, cluster_num, embed_axis, element):\n","        \"\"\"\n","        Computes the Gaussian Membership Function (GMF) for a node embedding.\n","\n","        Args:\n","            cluster_num (int): The cluster index.\n","            embed_axis (int): The specific embedding axis.\n","            element (float): The value of the embedding element to compute membership for.\n","\n","        Returns:\n","            torch.Tensor: The membership value of the element to the specified cluster using GMF.\n","        \"\"\"\n","        # Retrieve the mean and standard deviation\n","        mean = self.get_mean(cluster_num, embed_axis)\n","        stddev_tensor = self.get_stddev_tensor(embed_axis)\n","        # Handle zero standard deviation cases\n","        if stddev_tensor[cluster_num] != 0:\n","            gaussian = (element - mean) ** 2 / (2 * (stddev_tensor[cluster_num] ** 2))\n","        else:\n","            return 0.0\n","        # Compute the exponential Gaussian function\n","        return torch.exp(-gaussian)\n","\n","    def get_membership_array(self, embed_axis):\n","        \"\"\"\n","        Generates a membership array for all node embeddings along a specified embedding axis.\n","\n","        Args:\n","            embed_axis (int): The embedding axis for which membership values are computed.\n","\n","        Returns:\n","            torch.Tensor: A 2D tensor where each row corresponds to a node and each column represents\n","                        the membership degree of the node to a specific cluster.\n","                        Shape: (num_nodes, num_clusters).\n","        \"\"\"\n","        # Preallocate the membership array with zeros\n","        membership_array = torch.zeros((self.X.shape[0], self.centroid_array.shape[0]), device=device)\n","        # Iterate over all nodes\n","        for node_embed_num in range(self.X.shape[0]):\n","            # Iterate over all clusters\n","            for i in range(self.centroid_array.shape[0]):\n","                # Compute membership using the Gaussian Membership Function\n","                membership = self.gaussianMF(cluster_num=i, embed_axis=embed_axis,\n","                                            element=self.X[node_embed_num, embed_axis])\n","                membership_array[node_embed_num, i] = membership\n","        return membership_array\n"],"metadata":{"id":"vgkCnuL5Xgwh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JXPZYojTbBX"},"outputs":[],"source":["b = Antecedant(X = X,\n","               centroid_array = centroid_array,\n","               cluster_indices_array = cluster_indices_array)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JwarYhkDTbBX","outputId":"f8319c56-9b83-4053-edff-cc6eadab391b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/3r/s7htwqw902q6tm435h5z7f2c0000gn/T/ipykernel_91822/1769519963.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  cluster_ids = torch.tensor(self.cluster_indices_array[cluster_num], device=device)\n"]},{"data":{"text/plain":["tensor([[[0.8075, 0.9054, 0.9412, 0.9210, 0.9588],\n","         [0.5085, 0.7430, 0.8708, 0.7947, 0.9348],\n","         [0.9568, 0.9788, 0.9845, 0.9816, 0.9871],\n","         ...,\n","         [0.7661, 0.8840, 0.9286, 0.9033, 0.9508],\n","         [0.6774, 0.8358, 0.9003, 0.8634, 0.9328],\n","         [0.0092, 0.1240, 0.3545, 0.1940, 0.5735]],\n","\n","        [[0.9992, 0.9905, 0.9523, 0.9995, 0.9881],\n","         [0.8668, 0.9805, 0.9984, 0.9797, 1.0000],\n","         [0.6290, 0.8867, 0.9866, 0.9209, 0.9895],\n","         ...,\n","         [0.7951, 0.9573, 0.9999, 0.9642, 0.9986],\n","         [0.9348, 0.9965, 0.9897, 0.9925, 0.9988],\n","         [0.9525, 0.9989, 0.9852, 0.9953, 0.9978]],\n","\n","        [[0.9734, 0.9114, 1.0000, 0.9637, 1.0000],\n","         [0.9385, 0.9995, 0.9619, 0.9999, 0.9688],\n","         [0.9909, 0.9355, 0.9992, 0.9749, 0.9988],\n","         ...,\n","         [0.9989, 0.9544, 0.9966, 0.9834, 0.9964],\n","         [1.0000, 0.9640, 0.9942, 0.9875, 0.9944],\n","         [0.1684, 0.2995, 0.7196, 0.5667, 0.7960]],\n","\n","        ...,\n","\n","        [[0.6354, 0.9316, 0.7858, 0.7475, 0.7277],\n","         [0.8096, 0.9858, 0.8575, 0.8273, 0.7964],\n","         [0.9322, 0.8670, 0.9967, 0.9932, 0.9667],\n","         ...,\n","         [0.8197, 0.7772, 0.9993, 1.0000, 0.9878],\n","         [0.7573, 0.7326, 0.9959, 0.9980, 0.9940],\n","         [0.0017, 0.0239, 0.3751, 0.3531, 0.5846]],\n","\n","        [[0.7715, 0.8513, 0.9353, 0.8560, 0.9061],\n","         [0.8656, 0.9069, 0.9597, 0.8943, 0.9484],\n","         [0.9963, 0.9911, 0.9958, 0.9659, 0.9994],\n","         ...,\n","         [0.9743, 0.9967, 0.9990, 0.9932, 0.9857],\n","         [0.9676, 0.9949, 0.9984, 0.9946, 0.9824],\n","         [0.9621, 0.9934, 0.9979, 0.9956, 0.9798]],\n","\n","        [[0.9164, 0.9182, 0.9468, 0.9473, 0.9011],\n","         [0.7127, 0.9172, 0.9601, 0.9626, 0.9955],\n","         [0.7332, 0.9259, 0.9647, 0.9670, 0.9968],\n","         ...,\n","         [0.2246, 0.4362, 0.6180, 0.6260, 0.5830],\n","         [0.2027, 0.4145, 0.6005, 0.6088, 0.5673],\n","         [1.0000, 0.9918, 0.9930, 0.9927, 0.9650]]])"]},"execution_count":194,"metadata":{},"output_type":"execute_result"}],"source":["# calcualtes the 3-D membership array.\n","membership_array = []\n","for embed_axis in range(node_embed_dim):\n","    mem_array_per_axis = b.get_membership_array(embed_axis = embed_axis)\n","    membership_array.append(mem_array_per_axis)\n","membership_array = torch.stack(membership_array)\n","membership_array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"etaex-E4TbBX"},"outputs":[],"source":["### --------------------------------------------------- OPTIONAL ---------------------------------------------------###\n","# Run this code to eliminate any Nan values in the membership array.\n","# Chose the dimensions accordingly.\n","\n","#membership_array = membership_array[:, :, [0, 1, 2, 3]]\n","#membership_array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkYdLNeQTbBX"},"outputs":[],"source":["class Consequent():\n","    \"\"\"\n","    This class generates the crisp embeddings using the membership values generated by the Antecedant class.\n","\n","    Essentially, we fuzzified each of the embeddings for each node, clustered the nodes, found centroids,\n","    and calculated membership for each embedding. Now, we use that membership to output crisp memberships.\n","\n","    To do that, we generate sets with variances and treat them as the consequent fuzzy set from which crisp output is generated.\n","    \"\"\"\n","\n","    def __init__(self, X, centroid_array, cluster_indices_array):\n","        \"\"\"\n","        Parameters:\n","            X (np.ndarray): Dataset of node embeddings. Shape: (num_nodes, node_embed_dim).\n","            centroid_array (np.ndarray): Centroid array with cluster centroids. Shape: (num_clusters, node_embed_dim).\n","            cluster_indices_array (list): A list of lists, where each sublist contains indices of nodes\n","                                           belonging to a specific cluster.\n","        \"\"\"\n","\n","        self.X = torch.tensor(X, device=device)\n","        self.centroid_array = torch.tensor(centroid_array, device=device)\n","        self.cluster_indices_array = cluster_indices_array\n","\n","    def get_average_membership_array(self, membership_array):\n","        \"\"\"\n","        Calculates the average membership for each embedding dimension across all clusters.\n","\n","        Args:\n","            membership_array (torch.Tensor): The membership values of shape (node_embed_dim, num_nodes, num_clusters).\n","\n","        Returns:\n","            torch.Tensor: The average membership values of shape (node_embed_dim, num_nodes).\n","        \"\"\"\n","        return torch.mean(membership_array, dim=2)  # shape = (node_embed_dim, num_nodes)\n","\n","    def get_embed_axis_mean(self):\n","        \"\"\"\n","        Calculates the mean of each embedding axis.\n","\n","        Returns:\n","            torch.Tensor: The mean values for each embedding axis of shape (node_embed_dim,).\n","        \"\"\"\n","        a = self.X.transpose(dim0=1, dim1=0) #shape = (50, 5242)\n","        return torch.mean(a, axis = 1) #shape = (50,)\n","\n","    def get_embed_axis_variance(self):\n","        \"\"\"\n","        Calculates the variance of each embedding axis.\n","\n","        Returns:\n","            torch.Tensor: The variance values for each embedding axis of shape (node_embed_dim,).\n","        \"\"\"\n","        a = self.X.transpose(dim0=1, dim1=0)\n","        mean = self.get_embed_axis_mean()\n","        variance = torch.zeros(size = (node_embed_dim,))\n","        for i in range(node_embed_dim):\n","            x = torch.sqrt(torch.mean((a[i] - mean[i])**2))\n","            variance[i] += x\n","        return variance #shape = (50,)\n","\n","    def get_crisp_embeddings(self, average_membership_array):\n","        \"\"\"\n","        Generates the crisp embeddings using the average membership values.\n","\n","        Args:\n","            average_membership_array (torch.Tensor): The average membership values of shape (node_embed_dim, num_nodes).\n","\n","        Returns:\n","            torch.Tensor: The crisp embeddings of shape (num_nodes, node_embed_dim).\n","        \"\"\"\n","        a = self.X.transpose(dim0=1, dim1=0)\n","        mean = self.get_embed_axis_mean()\n","        variance = self.get_embed_axis_variance()\n","        new_X = torch.zeros(size = (node_embed_dim, self.X.shape[0]))\n","        for i in range(node_embed_dim):\n","            for j in range(self.X.shape[0]):\n","                if average_membership_array[i][j] == 0:\n","                    new_X[i][j] = a[i][j]\n","                else:\n","                    b = -1*torch.log(average_membership_array[i][j])\n","                    if(a[i][j] < 0):\n","                        b = -1*torch.sqrt(b)\n","                    else:\n","                        b = torch.sqrt(b)\n","                    b = b*variance[i] + mean[i]\n","                    new_X[i][j] = b\n","        new_X = torch.transpose(new_X, dim0=1, dim1=0)\n","        new_X.shape\n","        #new_X = new_X/np.linalg.norm(new_X, axis = 0)\n","        return new_X"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2lJF6iJITbBX"},"outputs":[],"source":["c = Consequent(X = X,\n","               centroid_array=centroid_array,\n","               cluster_indices_array = cluster_indices_array)"]},{"cell_type":"code","source":["average_membership = c.get_average_membership_array(membership_array = membership_array)\n","crisp = c.get_crisp_embeddings(average_membership_array = average_membership)\n","save_embeddings(filepath = embedding_filename, graph = G, embeddings = crisp)"],"metadata":{"id":"3e6eNzOOvDlD"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"graphgan","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}