{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanshgupta/opt/anaconda3/envs/graphgan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"/Users/vanshgupta/Desktop/AI_and_ML_reading_material/GraphGAN_Project/GraphGAN/bio-grid-human/bio-grid-human_dataset.txt1\" #used to generate graph and get the number of nodes\n",
    "filename = \"/Users/vanshgupta/Desktop/AI_and_ML_reading_material/GraphGAN_Project/Emb_Data/Emb/biogrid-human/Struc2Vec/emb.txt\" #used to read the file and get embeddings.\n",
    "k = 5 # k -> Number of clusters \n",
    "node_embed_dim = 50 # Dimension of node feature vector\n",
    "\n",
    "rng = np.random.default_rng(seed = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(x : torch.Tensor, noise_ratio : float, node_embed_dim : int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to a subset of nodes in a given tensor.\n",
    "\n",
    "    This function introduces noise to a fraction of the nodes in the input tensor `x`. The noise is \n",
    "    generated from a normal distribution with mean 0 and standard deviation 1. The number of nodes \n",
    "    to be noised is determined by the `noise_ratio` parameter.\n",
    "\n",
    "    Parameters:\n",
    "        x (torch.Tensor): The input tensor of shape `(num_nodes, node_embed_dim)` representing \n",
    "                          node embeddings.\n",
    "        noise_ratio (float): The fraction of nodes to which noise will be added. Should be a \n",
    "                             value between 0 and 1.\n",
    "        node_embed_dim (int): The dimensionality of the node embeddings.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The modified tensor `x` with noise added to a subset of nodes.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    num_nodes = x.shape[0] #fetch the number of nodes\n",
    "    num_nodes_to_add_noise = int(num_nodes * noise_ratio) #fetch the number of nodes that are to be noised\n",
    "    total_nodes = torch.arange(0 , num_nodes).tolist() #gives a list of nodes\n",
    "    nodes_to_noise = random.sample(total_nodes, num_nodes_to_add_noise) #gives the node-ids where noise is to be added.\n",
    "\n",
    "    noise_tensor = torch.normal(mean = 0,\n",
    "                                std = 1, \n",
    "                                size = (num_nodes_to_add_noise, node_embed_dim))\n",
    "    \n",
    "    x[nodes_to_noise] = noise_tensor\n",
    "    return x \n",
    "\n",
    "\n",
    "def read_embeddings(filename: Path, n_node: int, n_embed: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reads pretrained node embeddings from a file and returns them as a numpy array.\n",
    "\n",
    "    This function initializes an embedding matrix with random values and updates it with \n",
    "    the pretrained embeddings provided in the file. If a node does not have a pretrained \n",
    "    embedding in the file, its embedding will remain as the initialized random values.\n",
    "\n",
    "    Parameters:\n",
    "        filename (Path): Path to the file containing pretrained node embeddings.\n",
    "                         The file format is expected to have node embeddings on each \n",
    "                         line in the format: `node_id dim_1 dim_2 ... dim_n`, with the \n",
    "                         first line typically skipped (header).\n",
    "        n_node (int): The total number of nodes in the graph.\n",
    "        n_embed (int): The embedding dimensionality for each node.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A numpy array of shape `(n_node, n_embed)` representing the node embeddings.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the file and read all lines, skipping the first line (header)\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()[1:]\n",
    "\n",
    "        # Create an embedding matrix initialized with random normal values\n",
    "        embedding_matrix = rng.standard_normal(size=(n_node, n_embed))\n",
    "\n",
    "        # Iterate over each line in the file (representing a node embedding)\n",
    "        for line in lines:\n",
    "            emd = line.split()  # Split the line into node ID and embedding values\n",
    "            # Update the embedding matrix for the specific node ID\n",
    "            embedding_matrix[int(emd[0]), :] = str_list_to_float(emd[1:])\n",
    "\n",
    "        # Return the final embedding matrix\n",
    "        return embedding_matrix\n",
    "\n",
    "def save_embeddings(filepath : Path, graph : Any, embeddings : np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Saves node embeddings to a file in a specified format.\n",
    "\n",
    "    This function takes a graph, its corresponding embeddings, and a file path. It maps the \n",
    "    embeddings to the graph nodes, combines the node indices with their respective embeddings, \n",
    "    and writes the data to the file. The output file includes a header indicating the total \n",
    "    number of nodes and the embedding dimensionality, followed by the embeddings for each node.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (Path): Path to the file where embeddings will be saved.\n",
    "        graph (Any): A graph object (e.g., from NetworkX) containing node information.\n",
    "        embeddings (np.ndarray): A 2D numpy array of shape `(num_nodes, embedding_dim)` \n",
    "                                  containing node embeddings.\n",
    "\n",
    "    File Format:\n",
    "        The saved file has the following format:\n",
    "        - The first line contains the number of nodes and the embedding dimensionality, \n",
    "          separated by a tab.\n",
    "        - Each subsequent line corresponds to a node, containing the node ID followed \n",
    "          by its embedding values separated by spaces.\n",
    "    \"\"\"\n",
    "    # Map the embeddings to the node indices in the graph\n",
    "    new = embeddings[torch.tensor(np.array(graph.nodes()))]\n",
    "\n",
    "    # Get the node indices and reshape them into a column vector\n",
    "    index = np.array(graph.nodes()).reshape(-1, 1)\n",
    "\n",
    "    # Combine node indices with their embeddings into a single matrix\n",
    "    embedding_matrix = np.hstack([index, new])\n",
    "\n",
    "    # Convert the embedding matrix into a list of strings for saving\n",
    "    embedding_list = embedding_matrix.tolist()\n",
    "    embedding_str = [str(int(emb[0])) + \" \" + \" \".join([str(x) for x in emb[1:]]) + \"\\n\"\n",
    "                     for emb in embedding_list]\n",
    "\n",
    "    # Write the embeddings to the file\n",
    "    with open(filepath, \"w+\") as f:\n",
    "        # Include the header with number of nodes and embedding dimensionality\n",
    "        lines = [str(graph.number_of_nodes()) + \"\\t\" + str(embeddings.shape[1]) + \"\\n\"] + embedding_str\n",
    "        f.writelines(lines)\n",
    "\n",
    "\n",
    "def str_list_to_float(str_list : list[str]) -> list[float]:\n",
    "    \"\"\"Convert the string items of a list to float items\"\"\"\n",
    "    return [float(item) for item in str_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nodes in the graph : 9436\n",
      "The shape of the embedding vector (9436, 50)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(dataset,\n",
    "                sep = '\\t',\n",
    "                names = [\"NodeIDfrom\", \"NodeIDto\"])\n",
    "#create the graph networkx object from the above dataframe\n",
    "\n",
    "G = nx.from_pandas_edgelist(df = df,\n",
    "                             source = \"NodeIDfrom\",\n",
    "                             target = \"NodeIDto\",\n",
    "                             create_using=nx.Graph())\n",
    "\n",
    "X = read_embeddings(filename=filename,\n",
    "                                     n_node = len(G),\n",
    "                                     n_embed = 50)\n",
    "\n",
    "print(f\"Number of Nodes in the graph : {len(G)}\")\n",
    "print(f\"The shape of the embedding vector {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------------------------------------------------------------ TO ADD NOISE ------------------------------------------------------------ ###\n",
    "# Run this when you have to add noise to the original embeddings.\n",
    "X = add_noise(x = X, noise_ratio=0.02, node_embed_dim=50)\n",
    "X = np.array(X)\n",
    "\n",
    "# Save the noise-induced embeddings  \n",
    "error_emb_filename = \"/Users/vanshgupta/Desktop/AI_and_ML_reading_material/GraphGAN_Project/Emb_Data/Emb/biogrid-human/Struc2Vec/emb_2%_error.txt\"\n",
    "\n",
    "new = X[torch.tensor(np.array(G.nodes()))]\n",
    "index = np.array(G.nodes()).reshape(-1, 1)\n",
    "embedding_matrix = np.hstack([index, new])\n",
    "embedding_list = embedding_matrix.tolist()\n",
    "embedding_str = [str(int(emb[0])) + \" \" + \" \".join([str(x) for x in emb[1:]]) + \"\\n\"\n",
    "                  for emb in embedding_list]\n",
    "with open(error_emb_filename, \"w+\") as f:\n",
    "    lines = [str(G.number_of_nodes()) + \"\\t\" + str(node_embed_dim) + \"\\n\"] + embedding_str\n",
    "    f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed = 42)\n",
    "X = np.array(X)\n",
    "centroid = rng.standard_normal(size = (k, node_embed_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#K-Means Algorithm for node embeddings\n",
    "#the embediddings are 1xd dimensional.\n",
    "class KMeansNodeClustering:\n",
    "\n",
    "  def __init__(self, X, k, node_embed_dim):\n",
    "      self.k = k #k is the number of cluster centres\n",
    "      self.X = X #dataset consisting of node embeddings\n",
    "      self.node_embed_dim = node_embed_dim #dimensions of node embeddings.\n",
    "      self.centroid = None #these will be the centres of our distribution\n",
    "\n",
    "  @staticmethod\n",
    "  def euclidean_measure(centroid, node_embed):  # calculates the distance of the k-dimensional node from the centre\n",
    "      return np.sqrt(np.sum((centroid - node_embed)**2, axis=1))\n",
    "\n",
    "  def dimensional_mean(cluster_num, node_embed_dim, cluster_indices, cluster_centres): #calculates the mean of of the arrays, dimension-wise\n",
    "        axis_centre = np.zeros(node_embed_dim)\n",
    "        for i in range(node_embed_dim):\n",
    "            y = 0\n",
    "            tup = cluster_indices[cluster_num].shape\n",
    "            shape = tup[0]\n",
    "            for x in range(shape):\n",
    "                y += X[cluster_indices[cluster_num][x]][0][i]\n",
    "            mean = np.mean(y)\n",
    "            axis_centre[i] += mean\n",
    "        axis_centre = axis_centre/np.linalg.norm(axis_centre)\n",
    "        return cluster_centres.append(axis_centre)\n",
    "\n",
    "  def fit(self, max_iterations = 200):\n",
    "      rng = np.random.default_rng(seed = 69)\n",
    "      self.centroid = rng.standard_normal(size = (self.k, self.node_embed_dim))\n",
    "      self.centroid  = (self.centroid)/(np.max(self.centroid))\n",
    "      for _ in range(max_iterations):\n",
    "          y = []\n",
    "\n",
    "          for node_embed in self.X:\n",
    "                distance = KMeansNodeClustering.euclidean_measure(node_embed = np.array(node_embed),\n",
    "                                                                  centroid = centroid)\n",
    "                cluster_num = np.argmin(distance)\n",
    "                y.append(cluster_num)\n",
    "\n",
    "          y = np.array(y) #stores the clustur number each of the nodes belong to\n",
    "\n",
    "          cluster_indices = [] #to know which node belongs to which cluster\n",
    "\n",
    "          for i in range(self.k):\n",
    "                cluster_indices.append(np.argwhere(y == i)) #returns every node which belongs to the same cluster\n",
    "          cluster_indices = np.array(cluster_indices, dtype = object)\n",
    "          cluster_centres = [] #stores the centres of the clusters\n",
    "\n",
    "          for j, indices in enumerate(cluster_indices): #cluster_indices contains the cluster numbers and the indices that belong to a particular cluster\n",
    "                #i = cluster number\n",
    "                #indices = indices of the nodes that belong to i.\n",
    "                if len(indices) == 0:\n",
    "                    cluster_centres.append(self.centroid[i])\n",
    "                else:\n",
    "                    KMeansNodeClustering.dimensional_mean(\n",
    "                                                          cluster_num = j,\n",
    "                                                          node_embed_dim=node_embed_dim,\n",
    "                                                          cluster_indices = cluster_indices,\n",
    "                                                          cluster_centres=cluster_centres)\n",
    "\n",
    "          self.centroid = np.array(cluster_centres)\n",
    "          y = np.array(y)\n",
    "      return y, cluster_indices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_nodes = KMeansNodeClustering(X = X,\n",
    "                                       k = k,\n",
    "                                       node_embed_dim = node_embed_dim)\n",
    "#cluster_indices_id stores the number_id of the clusters each embeddings is related to\n",
    "#cluster_indices stores all the nodes that belong to one particular cluster, for all the clusters.\n",
    "cluster_indices_id, cluster_indices = clustered_nodes.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04203649, -0.02398007,  0.0543293 ,  0.03709349, -0.19481731,\n",
       "        -0.23199867,  0.11306756,  0.09367199, -0.18545094, -0.1798814 ,\n",
       "         0.14223191, -0.19863543, -0.01068128, -0.05251942, -0.02731857,\n",
       "        -0.02791057,  0.13005896,  0.12065515, -0.23498105, -0.29573511,\n",
       "        -0.06885951,  0.28131776,  0.31373932,  0.0564836 ,  0.02835249,\n",
       "         0.17190833, -0.03749068,  0.04751545, -0.2127734 , -0.01121337,\n",
       "         0.05824769, -0.09289639, -0.00321679, -0.08346256, -0.25157313,\n",
       "         0.00293849,  0.09485431,  0.00072263, -0.06408919, -0.0857017 ,\n",
       "         0.15478988,  0.04548804, -0.0902423 , -0.06233313,  0.31061596,\n",
       "         0.13110521,  0.05435116, -0.17786423,  0.13030271,  0.06361567],\n",
       "       [ 0.06533315,  0.07145934, -0.00340568,  0.01771328,  0.04248543,\n",
       "        -0.13292006,  0.07279786,  0.28650912, -0.39514107, -0.0756019 ,\n",
       "        -0.16507294, -0.25103149,  0.15143345,  0.23623347, -0.13639874,\n",
       "         0.11304678, -0.14141157, -0.1043319 , -0.23507586, -0.09364117,\n",
       "        -0.03142978,  0.19127127,  0.10525891, -0.11757997,  0.19045894,\n",
       "        -0.01909575, -0.0584672 ,  0.12310858, -0.19054761,  0.04072263,\n",
       "         0.0434127 , -0.04578014, -0.06968483,  0.04473553, -0.34484298,\n",
       "         0.20349013,  0.02492667, -0.00479006,  0.03546975, -0.12819093,\n",
       "         0.03486334,  0.07001355, -0.05824553, -0.00041928,  0.08637146,\n",
       "        -0.03871032,  0.00474526, -0.24548396, -0.03010856,  0.03837593],\n",
       "       [-0.2350341 ,  0.11465384,  0.08419881,  0.00066537, -0.14675996,\n",
       "        -0.10393565,  0.02785928,  0.04832209, -0.03380044, -0.04533558,\n",
       "         0.1480703 , -0.07442858, -0.17082582, -0.2059563 ,  0.00294693,\n",
       "        -0.02456867,  0.12850674,  0.117358  , -0.13718815, -0.30341089,\n",
       "         0.05606416,  0.14901568,  0.07662028,  0.1692209 ,  0.11321335,\n",
       "         0.29797653,  0.10401188,  0.01205001, -0.24487209, -0.17057141,\n",
       "         0.02365373, -0.05448095, -0.05675157, -0.09711738, -0.21811412,\n",
       "         0.01898014,  0.28603821,  0.10263301,  0.15507179,  0.06264906,\n",
       "         0.11010728, -0.15369604, -0.08062985,  0.04270471,  0.22790275,\n",
       "         0.11584922, -0.00548956, -0.18414958,  0.20201949, -0.12217226],\n",
       "       [ 0.02109805, -0.0587492 , -0.09026211, -0.00379318,  0.05763103,\n",
       "        -0.00971094,  0.17070019,  0.20635905, -0.32596951, -0.23958763,\n",
       "        -0.13609623, -0.10072951,  0.16085814,  0.06411112, -0.1085227 ,\n",
       "         0.13485912,  0.03819759, -0.007557  , -0.19735018, -0.07975441,\n",
       "        -0.03485608,  0.31954172,  0.22277049, -0.163339  ,  0.00648011,\n",
       "         0.16251303,  0.05156102,  0.01810484, -0.13357944,  0.11260671,\n",
       "        -0.00451271, -0.06457266, -0.25348256,  0.16031505, -0.30695902,\n",
       "         0.13396617, -0.01761219, -0.14094154, -0.01139965, -0.07116929,\n",
       "         0.18794304, -0.03976215, -0.04441246,  0.18570949,  0.16503294,\n",
       "        -0.01610075,  0.1411493 ,  0.00803486,  0.03430458,  0.14284106],\n",
       "       [-0.13444712, -0.01732933,  0.12267648,  0.07678385, -0.05946764,\n",
       "        -0.06502877,  0.17127646,  0.11306674, -0.16993957, -0.07881987,\n",
       "        -0.01942062, -0.27760845,  0.02364172, -0.00882099, -0.0863984 ,\n",
       "         0.01820585, -0.11283286,  0.0677167 , -0.2489457 , -0.14725581,\n",
       "        -0.01789761,  0.30940226,  0.24628529, -0.08833244,  0.24962051,\n",
       "         0.07014955, -0.02906363,  0.12684191, -0.29106036,  0.065991  ,\n",
       "        -0.12466546, -0.01513905, -0.11106629,  0.16000029, -0.31772092,\n",
       "         0.02283267, -0.03098832, -0.02929506, -0.05594867, -0.18636637,\n",
       "         0.10257759,  0.01887178, -0.06477859, -0.2602056 ,  0.21638814,\n",
       "         0.01033706, -0.03204254, -0.01540156,  0.15688282,  0.02571089]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_array = clustered_nodes.centroid #contains the centroids of all the clusteres.\n",
    "centroid_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/s7htwqw902q6tm435h5z7f2c0000gn/T/ipykernel_86342/978200109.py:2: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  cluster_indices_array = np.array([torch.tensor(np.squeeze(cluster_indices[0], axis = 1)),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([tensor([   0,    3,    4,  ..., 9433, 9434, 9435]),\n",
       "       tensor([  12,   13,   14,  ..., 9420, 9426, 9427]),\n",
       "       tensor([  27,   52,  137,  177,  195,  239,  336,  367,  386,  489,  504,  952,\n",
       "                987, 1348, 1350, 1351, 1352, 1522, 3021, 3142, 3294, 3419, 3501, 3553,\n",
       "               3632, 3677, 3681, 4126, 4258, 4807, 4808, 4809, 4810, 4811, 4812, 4814,\n",
       "               5071, 5089, 5241, 5273, 5534, 5536, 5628, 5660, 5674, 5772, 6265, 6539,\n",
       "               6809, 6810, 6888, 6924, 7192, 7529, 7540, 7939, 7941, 8698, 8722, 8777,\n",
       "               8822, 8842, 8868, 8873, 8875, 8881, 8888, 8899, 8982, 9078])           ,\n",
       "       tensor([   2,   18,   43,   44,   50,   54,   57,   65,   70,   80,   83,  110,\n",
       "                181,  231,  237,  268,  328,  350,  390,  413,  436,  459,  505,  519,\n",
       "                536,  572,  599,  619,  637,  655,  660,  688,  707,  733,  745,  761,\n",
       "                763,  779,  792,  828,  832,  844,  889,  936,  989, 1003, 1005, 1117,\n",
       "               1137, 1205, 1217, 1443, 1495, 1730, 1787, 1806, 2010, 2018, 2354, 2784,\n",
       "               2814, 2864, 2885, 3287, 3492, 3713, 3853, 3858, 3862, 3875, 3962, 3980,\n",
       "               4002, 4064, 4296, 4440, 4658, 5018, 5262, 5471, 5473, 6500, 6522, 7012,\n",
       "               7201, 7722, 8307, 8718, 9243, 9364])                                   ,\n",
       "       tensor([   1,    8,   11,   37,   71,   72,   82,   90,  105,  133,  140,  146,\n",
       "                152,  176,  183,  188,  189,  194,  197,  201,  232,  329,  387,  439,\n",
       "                445,  455,  474,  488,  492,  517,  556,  562,  568,  589,  613,  614,\n",
       "                649,  682,  700,  708,  718,  748,  758,  781,  821,  827,  859,  880,\n",
       "                883,  885,  897,  909,  913, 1076, 1099, 1423, 1463, 1502, 1519, 1566,\n",
       "               1756, 1804, 1999, 2032, 2120, 2301, 2556, 2663, 2866, 2953, 3246, 3308,\n",
       "               3337, 3616, 3806, 3811, 3819, 3923, 4030, 4067, 4315, 4665, 4833, 4840,\n",
       "               4868, 4958, 5100, 5428, 6124, 6375, 6576, 6787, 6797, 7250, 8423, 8902,\n",
       "               8994])                                                                 ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_indices = np.array(cluster_indices, dtype=object)\n",
    "cluster_indices_array = np.array([torch.tensor(np.squeeze(cluster_indices[0], axis = 1)),\n",
    "                                  torch.tensor(np.squeeze(cluster_indices[1], axis = 1)),\n",
    "                                  torch.tensor(np.squeeze(cluster_indices[2], axis = 1)),\n",
    "                                  torch.tensor(np.squeeze(cluster_indices[3], axis = 1)),\n",
    "                                  torch.tensor(np.squeeze(cluster_indices[4], axis = 1)),\n",
    "                                 ], dtype = object)\n",
    "\n",
    "\n",
    "cluster_indices_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class FuzzyLayer:\n",
    "    \"\"\"\n",
    "    This is the parent class which will contain variables for Antecedant, Inference and Consequent classes.\n",
    "\n",
    "    Args:\n",
    "        X: The dataset which contains all the embeddings. shape(no_of_nodes, node_embed_dim)\n",
    "        centroid_array: contains all the centroids of all the clusters. shape(no_of_clusters, node_embed_dim)\n",
    "        cluster_indices_array: contains all the indices that belong to one particular cluster. shape(no_of_clusters, *number_of_indices_per_cluster*)\n",
    "                                                                                               number_of_indices_per_cluster varies therefore it has no particular shape\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, centroid_array, cluster_indices_array):\n",
    "        self.X = torch.tensor(X, device=device, dtype=torch.float64)\n",
    "        self.centroid_array = torch.tensor(centroid_array, device=device, dtype=torch.float64)\n",
    "        self.cluster_indices_array = cluster_indices_array\n",
    "\n",
    "class Antecedant(FuzzyLayer):\n",
    "    \"\"\"\n",
    "    Antecedant part of the fuzzy logic system, it gives us membership functions for the node embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, centroid_array, cluster_indices_array):\n",
    "        super().__init__(X, centroid_array, cluster_indices_array)\n",
    "\n",
    "    def dot_product(self):\n",
    "        # Use matrix multiplication instead of nested loops for efficiency\n",
    "        dot_products = torch.matmul(self.X, self.centroid_array.T)\n",
    "        return dot_products\n",
    "\n",
    "    def get_points(self, cluster_num, embed_axis):\n",
    "        # Fetch points corresponding to the cluster_num and embed_axis\n",
    "        cluster_ids = torch.tensor(self.cluster_indices_array[cluster_num], device=device)\n",
    "        points = self.X[cluster_ids, embed_axis]\n",
    "        return points\n",
    "\n",
    "    def get_mean(self, cluster_num, embed_axis):\n",
    "        # Directly access the mean from centroid array\n",
    "        return self.centroid_array[cluster_num, embed_axis]\n",
    "\n",
    "    def get_standard_deviation(self, cluster_num, embed_axis):\n",
    "        # Compute the variance in a vectorized manner\n",
    "        points = self.get_points(cluster_num, embed_axis)\n",
    "        mean = self.get_mean(cluster_num, embed_axis)\n",
    "        variance = torch.var(points)\n",
    "        variance = torch.sqrt(variance)\n",
    "        return variance\n",
    "\n",
    "    def get_stddev_tensor(self, embed_axis):\n",
    "        # Vectorize variance computation for all clusters\n",
    "        stddev = torch.tensor([self.get_standard_deviation(cluster_num, embed_axis) for cluster_num in range(self.centroid_array.shape[0])], device=device)\n",
    "        return stddev\n",
    "\n",
    "    def gaussianMF(self, cluster_num, embed_axis, element):\n",
    "        # Vectorized Gaussian Membership Function calculation\n",
    "        mean = self.get_mean(cluster_num, embed_axis)\n",
    "        stddev_tensor = self.get_stddev_tensor(embed_axis)\n",
    "        if stddev_tensor[cluster_num] != 0:\n",
    "            gaussian = (element - mean) ** 2 / (2 * (stddev_tensor[cluster_num] ** 2))\n",
    "        else:\n",
    "            return 0.0\n",
    "        return torch.exp(-gaussian)\n",
    "\n",
    "    def get_membership_array(self, embed_axis):\n",
    "        # Preallocate the membership array\n",
    "        membership_array = torch.zeros((self.X.shape[0], self.centroid_array.shape[0]), device=device)\n",
    "        for node_embed_num in range(self.X.shape[0]):\n",
    "            for i in range(self.centroid_array.shape[0]):\n",
    "                membership = self.gaussianMF(cluster_num=i, embed_axis=embed_axis, element=self.X[node_embed_num, embed_axis])\n",
    "                membership_array[node_embed_num, i] = membership\n",
    "        return membership_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Antecedant(X = X,\n",
    "               centroid_array = centroid_array,\n",
    "               cluster_indices_array = cluster_indices_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/s7htwqw902q6tm435h5z7f2c0000gn/T/ipykernel_86342/1769519963.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cluster_ids = torch.tensor(self.cluster_indices_array[cluster_num], device=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[4.8005e-01, 7.1221e-01, 7.4032e-01, 9.4302e-01, 8.8516e-01],\n",
       "         [5.1398e-01, 4.9810e-01, 9.4329e-01, 9.1783e-01, 9.4693e-01],\n",
       "         [9.9959e-01, 9.7456e-01, 9.8215e-01, 9.9854e-01, 9.9809e-01],\n",
       "         ...,\n",
       "         [8.9800e-01, 8.3728e-01, 9.9987e-01, 9.8147e-01, 9.9597e-01],\n",
       "         [7.6906e-01, 7.1622e-01, 9.9038e-01, 9.6240e-01, 9.8380e-01],\n",
       "         [9.2085e-01, 8.6104e-01, 9.9993e-01, 9.8481e-01, 9.9757e-01]],\n",
       "\n",
       "        [[3.0571e-06, 4.3126e-04, 6.4834e-03, 2.6206e-01, 5.4608e-02],\n",
       "         [7.7162e-02, 3.0762e-01, 5.1135e-01, 7.4207e-01, 5.6244e-01],\n",
       "         [2.3254e-02, 8.5883e-02, 1.9370e-01, 6.7957e-01, 4.2083e-01],\n",
       "         ...,\n",
       "         [7.3100e-01, 9.1068e-01, 9.6022e-01, 9.5968e-01, 9.3365e-01],\n",
       "         [7.7662e-01, 9.3307e-01, 9.7227e-01, 9.6669e-01, 9.4634e-01],\n",
       "         [8.5849e-01, 9.6842e-01, 9.8982e-01, 9.7860e-01, 9.6765e-01]],\n",
       "\n",
       "        [[1.1245e-01, 2.2506e-01, 6.9831e-01, 6.0596e-01, 7.0057e-01],\n",
       "         [3.4045e-05, 1.3654e-03, 1.7379e-01, 1.3057e-01, 1.6243e-01],\n",
       "         [3.2608e-01, 5.6547e-01, 8.0755e-01, 8.8649e-01, 7.7403e-01],\n",
       "         ...,\n",
       "         [9.3341e-01, 9.8197e-01, 9.8345e-01, 9.9974e-01, 9.7470e-01],\n",
       "         [9.9514e-01, 9.9977e-01, 9.9765e-01, 9.9591e-01, 9.9419e-01],\n",
       "         [9.8894e-01, 9.9984e-01, 9.9598e-01, 9.9758e-01, 9.9160e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[9.7761e-10, 2.1735e-06, 2.4908e-02, 2.6720e-01, 2.8016e-03],\n",
       "         [2.8907e-01, 3.8855e-01, 7.9853e-01, 9.5748e-01, 8.1052e-01],\n",
       "         [7.7078e-12, 3.0133e-08, 1.0194e-02, 2.6471e-01, 2.3059e-03],\n",
       "         ...,\n",
       "         [9.9197e-01, 9.7942e-01, 9.9828e-01, 9.9865e-01, 9.9610e-01],\n",
       "         [9.3174e-01, 9.2116e-01, 9.8667e-01, 9.9997e-01, 9.9927e-01],\n",
       "         [9.4156e-01, 9.2970e-01, 9.8858e-01, 1.0000e+00, 9.9972e-01]],\n",
       "\n",
       "        [[8.0555e-01, 7.3962e-01, 9.7580e-01, 9.7639e-01, 9.6598e-01],\n",
       "         [5.0634e-01, 7.8244e-01, 8.5911e-01, 9.6746e-01, 8.7045e-01],\n",
       "         [5.7896e-01, 5.5162e-01, 9.2835e-01, 9.5016e-01, 9.1129e-01],\n",
       "         ...,\n",
       "         [7.8635e-01, 7.2288e-01, 9.7242e-01, 9.7436e-01, 9.6195e-01],\n",
       "         [9.1769e-01, 8.4528e-01, 9.9301e-01, 9.8803e-01, 9.8762e-01],\n",
       "         [9.2583e-01, 8.5387e-01, 9.9406e-01, 9.8889e-01, 9.8906e-01]],\n",
       "\n",
       "        [[8.3059e-02, 2.0770e-01, 6.4343e-01, 7.8278e-01, 5.6084e-01],\n",
       "         [8.2372e-01, 9.0665e-01, 9.9644e-01, 9.6499e-01, 9.6846e-01],\n",
       "         [9.4090e-01, 9.7386e-01, 9.9991e-01, 9.8494e-01, 9.9213e-01],\n",
       "         ...,\n",
       "         [9.9187e-01, 9.9830e-01, 9.9568e-01, 9.9509e-01, 9.9974e-01],\n",
       "         [9.9985e-01, 9.9963e-01, 9.9124e-01, 9.9809e-01, 9.9959e-01],\n",
       "         [9.9438e-01, 9.9913e-01, 9.9493e-01, 9.9578e-01, 9.9992e-01]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "membership_array = []\n",
    "for embed_axis in range(node_embed_dim):\n",
    "    mem_array_per_axis = b.get_membership_array(embed_axis = embed_axis)\n",
    "    membership_array.append(mem_array_per_axis)\n",
    "membership_array = torch.stack(membership_array)\n",
    "membership_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#membership_array = membership_array[:, :, [0, 1, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7825, 0.7935, 0.9832, 0.9271],\n",
       "         [0.4548, 0.5402, 0.7105, 0.7738],\n",
       "         [0.9512, 0.9475, 0.9999, 0.9853],\n",
       "         ...,\n",
       "         [0.7364, 0.7520, 0.9747, 0.9096],\n",
       "         [0.6389, 0.6637, 0.9527, 0.8697],\n",
       "         [0.5685, 0.5995, 0.9333, 0.8383]],\n",
       "\n",
       "        [[0.9994, 0.9729, 0.9529, 0.9939],\n",
       "         [0.8489, 0.9733, 0.9984, 0.9703],\n",
       "         [0.5832, 0.8158, 0.9865, 0.8572],\n",
       "         ...,\n",
       "         [0.7676, 0.9347, 0.9999, 0.9411],\n",
       "         [0.9267, 0.9972, 0.9899, 0.9922],\n",
       "         [0.9998, 0.9615, 0.9453, 0.9894]],\n",
       "\n",
       "        [[0.9658, 0.8643, 0.9663, 0.8856],\n",
       "         [0.9310, 0.9997, 0.8681, 0.9993],\n",
       "         [0.9875, 0.9048, 0.9542, 0.9164],\n",
       "         ...,\n",
       "         [0.9981, 0.9363, 0.9417, 0.9407],\n",
       "         [1.0000, 0.9520, 0.9338, 0.9531],\n",
       "         [0.9584, 0.8528, 0.9692, 0.8769]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5658, 0.8158, 0.8558, 0.8628],\n",
       "         [0.7698, 0.9426, 0.9121, 0.9163],\n",
       "         [0.9069, 0.8077, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [0.7643, 0.6653, 0.9931, 0.9937],\n",
       "         [0.6884, 0.5976, 0.9861, 0.9873],\n",
       "         [0.6291, 0.5466, 0.9794, 0.9810]],\n",
       "\n",
       "        [[0.7403, 0.7525, 0.8853, 0.6942],\n",
       "         [0.8462, 0.8450, 0.9368, 0.7723],\n",
       "         [0.9958, 0.9884, 0.9993, 0.9285],\n",
       "         ...,\n",
       "         [0.9696, 0.9894, 0.9820, 0.9885],\n",
       "         [0.9617, 0.9851, 0.9779, 0.9915],\n",
       "         [0.8721, 0.8679, 0.9486, 0.7929]],\n",
       "\n",
       "        [[0.8984, 0.8737, 0.9808, 0.9197],\n",
       "         [0.6630, 0.8391, 0.9248, 0.9484],\n",
       "         [0.6862, 0.8545, 0.9308, 0.9547],\n",
       "         ...,\n",
       "         [0.1616, 0.2382, 0.7131, 0.4957],\n",
       "         [0.1426, 0.2177, 0.6967, 0.4756],\n",
       "         [0.7317, 0.7345, 0.9443, 0.8429]]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#membership_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np  # Only if absolutely necessary\n",
    "\n",
    "class Consequent(FuzzyLayer):\n",
    "    \"\"\"\n",
    "    This class generates the crisp embeddings using the membership values generated by the Antecedant class.\n",
    "\n",
    "    Essentially, we fuzzified each of the embeddings for each node, clustered the nodes, found centroids,\n",
    "    and calculated membership for each embedding. Now, we use that membership to output crisp memberships.\n",
    "\n",
    "    To do that, we generate sets with variances and treat them as the consequent fuzzy set from which crisp output is generated.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, centroid_array, cluster_indices_array):\n",
    "        super().__init__(X, centroid_array, cluster_indices_array)\n",
    "\n",
    "    def get_average_membership_array(self, membership_array):\n",
    "        \"\"\"\n",
    "        Calculates the average membership for each embedding dimension across all clusters.\n",
    "\n",
    "        Args:\n",
    "            membership_array (torch.Tensor): The membership values of shape (node_embed_dim, num_nodes, num_clusters).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The average membership values of shape (node_embed_dim, num_nodes).\n",
    "        \"\"\"\n",
    "        return torch.mean(membership_array, dim=2)  # shape = (node_embed_dim, num_nodes)\n",
    "\n",
    "    def get_embed_axis_mean(self):\n",
    "        \"\"\"\n",
    "        Calculates the mean of each embedding axis.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The mean values for each embedding axis of shape (node_embed_dim,).\n",
    "        \"\"\"\n",
    "        a = self.X.transpose(dim0=1, dim1=0) #shape = (50, 5242)\n",
    "        return torch.mean(a, axis = 1) #shape = (50,)\n",
    "\n",
    "    def get_embed_axis_variance(self):\n",
    "        \"\"\"\n",
    "        Calculates the variance of each embedding axis.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The variance values for each embedding axis of shape (node_embed_dim,).\n",
    "        \"\"\"\n",
    "        a = self.X.transpose(dim0=1, dim1=0)\n",
    "        mean = self.get_embed_axis_mean()\n",
    "        variance = torch.zeros(size = (node_embed_dim,))\n",
    "        for i in range(node_embed_dim):\n",
    "            x = torch.sqrt(torch.mean((a[i] - mean[i])**2))\n",
    "            variance[i] += x\n",
    "        return variance #shape = (50,)\n",
    "\n",
    "    def get_crisp_embeddings(self, average_membership_array):\n",
    "        \"\"\"\n",
    "        Generates the crisp embeddings using the average membership values.\n",
    "\n",
    "        Args:\n",
    "            average_membership_array (torch.Tensor): The average membership values of shape (node_embed_dim, num_nodes).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The crisp embeddings of shape (num_nodes, node_embed_dim).\n",
    "        \"\"\"\n",
    "        a = self.X.transpose(dim0=1, dim1=0)\n",
    "        mean = self.get_embed_axis_mean()\n",
    "        variance = self.get_embed_axis_variance()\n",
    "        new_X = torch.zeros(size = (node_embed_dim, self.X.shape[0]))\n",
    "        for i in range(node_embed_dim):\n",
    "            for j in range(self.X.shape[0]):\n",
    "                if average_membership_array[i][j] == 0:\n",
    "                    new_X[i][j] = a[i][j]\n",
    "                else:\n",
    "                    b = -1*torch.log(average_membership_array[i][j])\n",
    "                    if(a[i][j] < 0):\n",
    "                        b = -1*torch.sqrt(b)\n",
    "                    else:\n",
    "                        b = torch.sqrt(b)\n",
    "                    b = b*variance[i] + mean[i]\n",
    "                    new_X[i][j] = b\n",
    "        new_X = torch.transpose(new_X, dim0=1, dim1=0)\n",
    "        new_X.shape\n",
    "        #new_X = new_X/np.linalg.norm(new_X, axis = 0)\n",
    "        return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Consequent(X = X,\n",
    "               centroid_array=centroid_array,\n",
    "               cluster_indices_array = cluster_indices_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 9436])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_membership = c.get_average_membership_array(membership_array = membership_array)\n",
    "average_membership \n",
    "average_membership.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9436,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2507, -0.8600,  0.5219,  ..., -1.3424,  0.3504,  0.5811],\n",
       "        [-0.3088,  0.4770,  0.8776,  ...,  0.1443, -0.1686, -0.0680],\n",
       "        [-0.0847, -0.5847, -0.2775,  ...,  0.8069,  0.4502, -0.0019],\n",
       "        ...,\n",
       "        [-0.1623,  0.1743, -0.0270,  ..., -0.3273,  0.3599,  0.1165],\n",
       "        [-0.2193,  0.1557,  0.0896,  ..., -0.1586,  0.2853,  0.1086],\n",
       "        [-0.1498,  0.1190,  0.0198,  ..., -0.1663,  0.2794,  0.1132]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crisp = c.get_crisp_embeddings(average_membership_array = average_membership)\n",
    "norm = np.linalg.norm(crisp, axis = 1)\n",
    "print(norm.shape)\n",
    "for i in range(crisp.shape[0]):\n",
    "    crisp[i] = crisp[i]\n",
    "crisp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2507, -0.8600,  0.5219,  ..., -1.3424,  0.3504,  0.5811],\n",
       "        [-0.3088,  0.4770,  0.8776,  ...,  0.1443, -0.1686, -0.0680],\n",
       "        [-0.0847, -0.5847, -0.2775,  ...,  0.8069,  0.4502, -0.0019],\n",
       "        ...,\n",
       "        [-0.1646,  0.1358,  0.0897,  ..., -0.3266,  0.3130,  0.1090],\n",
       "        [-0.1773,  0.1142,  0.0874,  ..., -0.1209,  0.2371,  0.1081],\n",
       "        [-0.1498,  0.1190,  0.0198,  ..., -0.1663,  0.2794,  0.1132]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crisp[torch.tensor(np.array(G.nodes()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "embedding_filename = \"/Users/vanshgupta/Desktop/AI_and_ML_reading_material/GraphGAN_Project/Emb_Data/Emb/biogrid-human/Struc2Vec/fuzzy_emb_2%_error.txt\"\n",
    "embeddings = crisp[torch.tensor(np.array(G.nodes()))]\n",
    "index = np.array(G.nodes()).reshape(-1, 1)\n",
    "embedding_matrix = np.hstack([index, embeddings])\n",
    "embedding_list = embedding_matrix.tolist()\n",
    "embedding_str = [str(int(emb[0])) + \" \" + \" \".join([str(x) for x in emb[1:]]) + \"\\n\"\n",
    "                  for emb in embedding_list]\n",
    "with open(embedding_filename, \"w+\") as f:\n",
    "    lines = [str(G.number_of_nodes()) + \"\\t\" + str(node_embed_dim) + \"\\n\"] + embedding_str\n",
    "    f.writelines(lines)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
